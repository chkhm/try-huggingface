{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying ðŸ¤— HuggingFace Transformers\n",
    "\n",
    "Make sure you install the dependencies from `requirements.txt` before executing cells in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generator pipeline. In this case, use the `text2text` for NLP processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text2text-generation\", model=\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qna/git/try-huggingface/venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:836: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750014229.750142 1167729 service.cc:152] XLA service 0x16c835250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750014229.750214 1167729 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-06-15 15:03:49.757461: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1750014229.820637 1167729 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'machine learning is a key to a successful production environment . a foundational process'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize\n",
    "generator(\"summarize: Machine Learning in production environments is largely seen as the ultimate goal. Sometimes, deploying models can be difficult when automation is not part of the workflow. Creating a foundational process that is reliable and automated is complex and requires commitment from the team and the organization as a whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'positive'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment\n",
    "generator(\"sst2 sentence: Automation takes hard work but allows you to have a solid deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'negative'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment\n",
    "generator(\"sst2 sentence: This course is not very well documented...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'not_entailment'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions\n",
    "generator(\"question: Is deploying models into production hard?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '2006'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions\n",
    "generator(\"question: When was president Biden elected as US President?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'where is Rome?'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions\n",
    "generator(\"question: Where is Rome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"L'automatisation exige beaucoup de travail, mais vous permet d'avoir un dÃ©\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translation\n",
    "generator(\"translate English to French: Automation takes hard work but allows you to have a solid deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create other generation objects by calling in other models as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "gpt2_generator = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"When was president Biden elected as US President?\\n\\nBiden was elected president of the United States on January 7, 2001. He was sworn in the same day he was sworn into office.\\n\\nWhat is the relationship between our two countries with respect to national security issues?\\n\\nOur security relationship continues to be strong, strong, strong, strong. And if I could go through one I would say our relationship is the most dynamic I think among our closest friends.\\n\\nWhat would your plan be for our relationship with the United States be if there were a war in Libya and that we would have to pull out?\\n\\nWe would be able to keep our resources in place and have the capability to maintain our alliances and have diplomatic and military support. We would have some diplomatic support, but because of our geographic and location limitations on the Middle East and our desire to keep our resources, we never had that. We had a lot of difficulties with Libya and I wanted to maintain that.\\n\\nThat is why I will not be the US secretary of states when it comes to military interventions in other locations.\\n\\nWhen Obama was in office, he spoke about, let's say, our military intervention in Iraq. What was there to do about that?\\n\\nThe US entered into a mutual defense agreement with Iraq because there didn't exist any military power on both sides of the border. That is our understanding of what made Iraq possible. The other people that we have, I think, the greatest fear that is that if the United States were to intervene in Libya, we could give them the capability to attack Libya now and the people in that country might be frightened. So it has worked out very well.\\n\\nWhat about the possibility for North Korean attack? It is something I don't know that the Obama administration has had to debate. I'll say at this point, however important the United States' involvement can be to the stability of the situation in Libya, and to their long-term goal, to prevent those two regimes from having a ballistic missile, to degrade North Korea. So that's something that I don't really have to weigh.\\n\\nWhat would become of ISIS and a similar jihadist organization if it was a threat to the United States?\\n\\nIf they were to be attacked, they have the physical capacity. Whether they go into civilian territory, whether ISIS might be the result of terrorist violence that they've created, will make the same mistake as if they were attacked in a military-industrial complex, which we did that in 2010. We couldn't afford that\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_generator(\"When was president Biden elected as US President?\", max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
